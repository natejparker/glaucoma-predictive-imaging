{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f2715cee",
   "metadata": {},
   "source": [
    "Link to Kaggle dataset: https://www.kaggle.com/datasets/deathtrooper/multichannel-glaucoma-benchmark-dataset/data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e4ed9488",
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "import pandas as pd\n",
    "import keras\n",
    "import os\n",
    "import numpy as np\n",
    "from keras.layers import Dense, Activation, Flatten, Dropout, GlobalAveragePooling2D, Conv2D, BatchNormalization, MaxPooling2D, Input, Concatenate, ReLU, AveragePooling2D, UpSampling2D, GlobalMaxPooling2D\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, ModelCheckpoint\n",
    "from tensorflow.keras.optimizers import SGD, Adam\n",
    "from keras.preprocessing import image\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.applications.mobilenet_v3 import preprocess_input \n",
    "from keras.layers import GlobalMaxPool2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "be763ad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unzip files for processing\n",
    "with zipfile.ZipFile(\"full-fundus.zip\",\"r\") as zip_ref:\n",
    "    zip_ref.extractall(\"full-fundus\")\n",
    "    \n",
    "with zipfile.ZipFile(\"blood-vessel.zip\",\"r\") as zip_ref:\n",
    "    zip_ref.extractall(\"blood-vessel\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d96726cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in metadata, and filter for a specific subset of images\n",
    "# TODO: will add more variety of images later\n",
    "image_data = pd.read_csv('metadata.csv')\n",
    "image_data = image_data[image_data['names'].str.contains('FIVES', case=True) | image_data['names'].str.contains('HAGIS', case=True)\n",
    "                       | image_data['names'].str.contains('LES-AV', case=True) | image_data['names'].str.contains('G1020', case=True)]\n",
    "#g1020 = image_data[image_data['names'].str.contains('G1020', case=True)]\n",
    "#g1020 = g1020[g1020[\"fundus_oc_seg\"] != \"Not Visible\"]\n",
    "\n",
    "#image_data = pd.concat([subset_image_data, g1020])\n",
    "image_data = image_data[['types', 'fundus', 'names']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "762832d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 1452 entries, 4524 to 12448\n",
      "Data columns (total 3 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   types   1452 non-null   int64 \n",
      " 1   fundus  1452 non-null   object\n",
      " 2   names   1452 non-null   object\n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 45.4+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# There are some invalid data types for relevant columns\n",
    "print(image_data.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "69f1e91b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change datatypes to the desired values\n",
    "image_data['types'] = image_data['types'].astype('string')\n",
    "image_data['fundus'] = image_data['fundus'].astype('string')\n",
    "image_data['names'] = image_data['names'].astype('string')\n",
    "image_data['image_names'] = image_data['names'] + '.png'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6c6a7a20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 1452 entries, 4524 to 12448\n",
      "Data columns (total 4 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   types        1452 non-null   string\n",
      " 1   fundus       1452 non-null   string\n",
      " 2   names        1452 non-null   string\n",
      " 3   image_names  1452 non-null   string\n",
      "dtypes: string(4)\n",
      "memory usage: 56.7 KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(image_data.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0ef71356",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of healthy samples: 985\n",
      "Number of unhealthy samples: 467\n"
     ]
    }
   ],
   "source": [
    "# Randomize data \n",
    "image_data_random = image_data.sample(frac=1, random_state=1)\n",
    "\n",
    "# Split into healthy and glaucoma positive sets\n",
    "healthy = image_data_random[image_data_random['types'] == \"0\"]\n",
    "glaucoma = image_data_random[image_data_random['types'] == \"1\"]\n",
    "\n",
    "print(f\"Number of healthy samples: {len(healthy)}\")\n",
    "print(f\"Number of unhealthy samples: {len(glaucoma)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0f03a755",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test size: 437\n",
      "Train size: 1015\n"
     ]
    }
   ],
   "source": [
    "# Partition data into test and train sets\n",
    "healthy_train_size = 689\n",
    "glaucoma_train_size = 326\n",
    "\n",
    "healthy_test_subset = image_data_random.head(len(healthy) - healthy_train_size)\n",
    "glaucoma_test_subset = image_data_random.head(len(glaucoma) - glaucoma_train_size)\n",
    "test_subset = pd.concat([healthy_test_subset, glaucoma_test_subset])\n",
    "\n",
    "healthy_train_subset = image_data_random.tail(healthy_train_size)\n",
    "glaucoma_train_subset = image_data_random.tail(glaucoma_train_size)\n",
    "train_subset = pd.concat([healthy_train_subset, glaucoma_train_subset])\n",
    "\n",
    "print(f\"Test size: {len(test_subset)}\")\n",
    "print(f\"Train size: {len(train_subset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "59be0863",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1015 validated image filenames belonging to 2 classes.\n",
      "Found 437 validated image filenames belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_data_generator = ImageDataGenerator(preprocessing_function= preprocess_input)\n",
    "\n",
    "flow_train_data = train_data_generator.flow_from_dataframe(dataframe=train_subset, \n",
    "                                            batch_size= 8, \n",
    "                                            shuffle=True, \n",
    "                                            x_col=\"image_names\", \n",
    "                                            y_col=\"types\", \n",
    "                                            validate_filenames=True, \n",
    "                                            target_size=(224, 224), \n",
    "                                            directory='full-fundus/full-fundus/', \n",
    "                                            color_mode='rgb')\n",
    "\n",
    "test_data_generator = ImageDataGenerator(preprocessing_function= preprocess_input)\n",
    "\n",
    "flow_test_data = train_data_generator.flow_from_dataframe(dataframe=test_subset, \n",
    "                                            batch_size= 1, \n",
    "                                            shuffle=False, \n",
    "                                            x_col=\"image_names\", \n",
    "                                            y_col=\"types\", \n",
    "                                            validate_filenames=True, \n",
    "                                            target_size=(224, 224), \n",
    "                                            directory='full-fundus/full-fundus/', \n",
    "                                            color_mode='rgb')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fbe795f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ThomasMcBride/anaconda3/lib/python3.11/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:120: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 515ms/step - auc: 0.5567 - binary_accuracy: 0.5446 - loss: 4.4908 - precision: 0.5446 - recall: 0.5446 - val_auc: 0.4181 - val_binary_accuracy: 0.4256 - val_loss: 2.2646 - val_precision: 0.4256 - val_recall: 0.4256 - learning_rate: 1.0000e-05\n",
      "Epoch 2/20\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 197ms/step - auc: 0.5271 - binary_accuracy: 0.5248 - loss: 5.1763 - precision: 0.5248 - recall: 0.5248 - val_auc: 0.0000e+00 - val_binary_accuracy: 0.0000e+00 - val_loss: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - learning_rate: 1.0000e-05\n",
      "Epoch 3/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-29 22:07:48.424712: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n",
      "/Users/ThomasMcBride/anaconda3/lib/python3.11/contextlib.py:155: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
      "  self.gen.throw(typ, value, traceback)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 490ms/step - auc: 0.5850 - binary_accuracy: 0.5533 - loss: 4.2939 - precision: 0.5533 - recall: 0.5533 - val_auc: 0.4610 - val_binary_accuracy: 0.4485 - val_loss: 1.9990 - val_precision: 0.4485 - val_recall: 0.4485 - learning_rate: 1.0000e-05\n",
      "Epoch 4/20\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 217ms/step - auc: 0.5354 - binary_accuracy: 0.5287 - loss: 4.7326 - precision: 0.5287 - recall: 0.5287 - val_auc: 0.0000e+00 - val_binary_accuracy: 0.0000e+00 - val_loss: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - learning_rate: 1.0000e-05\n",
      "Epoch 5/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-29 22:07:58.774087: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 539ms/step - auc: 0.6330 - binary_accuracy: 0.6467 - loss: 3.9308 - precision: 0.6467 - recall: 0.6467 - val_auc: 0.4898 - val_binary_accuracy: 0.4737 - val_loss: 1.7964 - val_precision: 0.4737 - val_recall: 0.4737 - learning_rate: 8.0000e-06\n",
      "Epoch 6/20\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 203ms/step - auc: 0.6107 - binary_accuracy: 0.6054 - loss: 3.7791 - precision: 0.6054 - recall: 0.6054 - val_auc: 0.0000e+00 - val_binary_accuracy: 0.0000e+00 - val_loss: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - learning_rate: 8.0000e-06\n",
      "Epoch 7/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-29 22:08:09.593118: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 498ms/step - auc: 0.6558 - binary_accuracy: 0.6122 - loss: 3.5974 - precision: 0.6122 - recall: 0.6122 - val_auc: 0.5138 - val_binary_accuracy: 0.5103 - val_loss: 1.6514 - val_precision: 0.5103 - val_recall: 0.5103 - learning_rate: 8.0000e-06\n",
      "Epoch 8/20\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 204ms/step - auc: 0.5677 - binary_accuracy: 0.5378 - loss: 4.3887 - precision: 0.5378 - recall: 0.5378 - val_auc: 0.0000e+00 - val_binary_accuracy: 0.0000e+00 - val_loss: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - learning_rate: 6.4000e-06\n",
      "Epoch 9/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-29 22:08:19.811296: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m 7/15\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 204ms/step - auc: 0.6498 - binary_accuracy: 0.6626 - loss: 3.3729 - precision: 0.6626 - recall: 0.6626"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-29 22:08:21.258818: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 379ms/step - auc: 0.6529 - binary_accuracy: 0.6330 - loss: 3.2614 - precision: 0.6330 - recall: 0.6330 - val_auc: 0.5158 - val_binary_accuracy: 0.5172 - val_loss: 1.5881 - val_precision: 0.5172 - val_recall: 0.5172 - learning_rate: 5.1200e-06\n",
      "Epoch 10/20\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 219ms/step - auc: 0.5444 - binary_accuracy: 0.5591 - loss: 4.2193 - precision: 0.5591 - recall: 0.5591 - val_auc: 0.0000e+00 - val_binary_accuracy: 0.0000e+00 - val_loss: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - learning_rate: 5.1200e-06\n",
      "Epoch 11/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-29 22:08:28.867141: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 505ms/step - auc: 0.6431 - binary_accuracy: 0.5740 - loss: 3.6009 - precision: 0.5740 - recall: 0.5740 - val_auc: 0.5255 - val_binary_accuracy: 0.5172 - val_loss: 1.5238 - val_precision: 0.5172 - val_recall: 0.5172 - learning_rate: 4.0960e-06\n",
      "Epoch 12/20\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 214ms/step - auc: 0.5141 - binary_accuracy: 0.5477 - loss: 4.1084 - precision: 0.5477 - recall: 0.5477 - val_auc: 0.0000e+00 - val_binary_accuracy: 0.0000e+00 - val_loss: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - learning_rate: 3.2768e-06\n",
      "Epoch 13/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-29 22:08:39.370998: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 504ms/step - auc: 0.6179 - binary_accuracy: 0.5770 - loss: 3.6879 - precision: 0.5770 - recall: 0.5770 - val_auc: 0.5229 - val_binary_accuracy: 0.5332 - val_loss: 1.4960 - val_precision: 0.5332 - val_recall: 0.5332 - learning_rate: 2.6214e-06\n",
      "Epoch 14/20\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 214ms/step - auc: 0.5243 - binary_accuracy: 0.5050 - loss: 4.3300 - precision: 0.5050 - recall: 0.5050 - val_auc: 0.0000e+00 - val_binary_accuracy: 0.0000e+00 - val_loss: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - learning_rate: 2.0972e-06\n",
      "Epoch 15/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-29 22:08:49.849112: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 499ms/step - auc: 0.6725 - binary_accuracy: 0.6346 - loss: 3.5503 - precision: 0.6346 - recall: 0.6346 - val_auc: 0.5177 - val_binary_accuracy: 0.5309 - val_loss: 1.4895 - val_precision: 0.5309 - val_recall: 0.5309 - learning_rate: 1.6777e-06\n",
      "Epoch 16/20\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 202ms/step - auc: 0.5486 - binary_accuracy: 0.5767 - loss: 3.6820 - precision: 0.5767 - recall: 0.5767 - val_auc: 0.0000e+00 - val_binary_accuracy: 0.0000e+00 - val_loss: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - learning_rate: 1.3422e-06\n",
      "Epoch 17/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-29 22:09:00.096109: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 495ms/step - auc: 0.5475 - binary_accuracy: 0.5371 - loss: 3.8337 - precision: 0.5371 - recall: 0.5371 - val_auc: 0.5157 - val_binary_accuracy: 0.5195 - val_loss: 1.4894 - val_precision: 0.5195 - val_recall: 0.5195 - learning_rate: 1.0737e-06\n",
      "Epoch 18/20\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 86ms/step - auc: 0.5490 - binary_accuracy: 0.5132 - loss: 3.3552 - precision: 0.5132 - recall: 0.5132 - val_auc: 0.0000e+00 - val_binary_accuracy: 0.0000e+00 - val_loss: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - learning_rate: 1.0000e-06\n",
      "Epoch 19/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-29 22:09:08.645071: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n",
      "2024-03-29 22:09:08.651869: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 514ms/step - auc: 0.6223 - binary_accuracy: 0.6325 - loss: 3.9253 - precision: 0.6325 - recall: 0.6325 - val_auc: 0.5152 - val_binary_accuracy: 0.5126 - val_loss: 1.4891 - val_precision: 0.5126 - val_recall: 0.5126 - learning_rate: 1.0000e-06\n",
      "Epoch 20/20\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 247ms/step - auc: 0.6696 - binary_accuracy: 0.6547 - loss: 2.8791 - precision: 0.6547 - recall: 0.6547 - val_auc: 0.0000e+00 - val_binary_accuracy: 0.0000e+00 - val_loss: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - learning_rate: 1.0000e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-29 22:09:20.057000: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n"
     ]
    }
   ],
   "source": [
    "def conv_model(image_size):\n",
    "    \n",
    "    m_input = keras.Input(shape=(image_size, image_size, 3))\n",
    "    transfer = keras.applications.MobileNetV3Large(\n",
    "        weights='imagenet', include_top= False, input_tensor= m_input, alpha=0.75\n",
    "    )\n",
    "    m_output = Dropout(0.5)(transfer.output)\n",
    "    m_output = Conv2D(filters=256, kernel_size=1)(m_output) \n",
    "    m_output = GlobalMaxPool2D()(m_output)\n",
    "    m_output = Dropout(0.5)(m_output)\n",
    "    m_output = Dense(2, activation='softmax')(m_output)\n",
    "\n",
    "    return keras.Model(inputs=m_input, outputs=m_output)\n",
    "\n",
    "model = conv_model(image_size=224)\n",
    "\n",
    "# Reduce the learning rate if an epoch occurs where there is no improvement to the output of the loss function\n",
    "reduce_lr = ReduceLROnPlateau(monitor='loss', factor=0.8, patience=1, min_lr=1e-6)\n",
    "\n",
    "# Using the Adam optimizer with binary cross entropy, compile the model using the given metrics\n",
    "model.compile(optimizer= Adam(1e-5), \n",
    "              loss='binary_crossentropy', \n",
    "              metrics=['binary_accuracy',keras.metrics.AUC(),keras.metrics.Precision(), keras.metrics.Recall()])\n",
    "\n",
    "trained_model = model.fit(flow_train_data, \n",
    "                    steps_per_epoch= len(flow_train_data) // 8,\n",
    "                    validation_data= flow_test_data, \n",
    "                    validation_steps= len(flow_test_data), \n",
    "                    epochs=20, \n",
    "                    callbacks=[reduce_lr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "31818c82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<keras.src.callbacks.history.History object at 0x1549e6810>\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 366ms/step\n",
      "[[0.9604122  0.03958783]]\n",
      "Prediction: Glaucoma, with 96.04122042655945% confidence\n"
     ]
    }
   ],
   "source": [
    "# Demonstration:\n",
    "print(trained_model)\n",
    "img_path = 'full-fundus/full-fundus/OIA-ODIR-TEST-ONLINE-252.png'\n",
    "img = image.load_img(img_path, target_size=(224, 224))\n",
    " \n",
    "img_array_representation = np.expand_dims(image.img_to_array(img), axis=0)\n",
    "img_array_representation = preprocess_input(img_array_representation)  # Assuming preprocess_input is defined in your code\n",
    "\n",
    "prediction = model.predict(img_array_representation)\n",
    "print(prediction)\n",
    "# Interpret the prediction\n",
    "if prediction[0][0] > prediction[0][1]:\n",
    "    print(f\"Prediction: Glaucoma, with {prediction[0][0] * 100}% confidence\")\n",
    "else:\n",
    "    print(f\"Prediction: Healthy, with {prediction[0][1] * 100}% confidence\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46c8707a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
