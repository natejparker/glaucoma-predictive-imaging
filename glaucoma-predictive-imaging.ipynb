{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ee4cafbe",
   "metadata": {},
   "source": [
    "Link to Kaggle dataset: https://www.kaggle.com/datasets/deathtrooper/multichannel-glaucoma-benchmark-dataset/data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4faac155",
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "import pandas as pd\n",
    "import keras\n",
    "import os\n",
    "import numpy as np\n",
    "from keras.layers import Dense, Activation, Flatten, Dropout, GlobalAveragePooling2D, Conv2D, BatchNormalization, MaxPooling2D, Input, Concatenate, ReLU, AveragePooling2D, UpSampling2D, GlobalMaxPooling2D\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, ModelCheckpoint\n",
    "from tensorflow.keras.optimizers import SGD, Adam\n",
    "from keras.preprocessing import image\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.applications.mobilenet_v3 import preprocess_input \n",
    "from keras.layers import GlobalMaxPool2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "be763ad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unzip files for processing\n",
    "with zipfile.ZipFile(\"full-fundus.zip\",\"r\") as zip_ref:\n",
    "    zip_ref.extractall(\"full-fundus\")\n",
    "    \n",
    "with zipfile.ZipFile(\"blood-vessel.zip\",\"r\") as zip_ref:\n",
    "    zip_ref.extractall(\"blood-vessel\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d96726cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in metadata, and filter for a specific subset of images\n",
    "# TODO: will add more variety of images later\n",
    "image_data = pd.read_csv('metadata.csv')\n",
    "image_data = image_data[image_data['names'].str.contains('FIVES', case=True) | image_data['names'].str.contains('HAGIS', case=True)\n",
    "                       | image_data['names'].str.contains('LES-AV', case=True)]\n",
    "image_data = image_data[['types', 'fundus', 'names']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "56da23b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 432 entries, 4524 to 12448\n",
      "Data columns (total 3 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   types   432 non-null    int64 \n",
      " 1   fundus  432 non-null    object\n",
      " 2   names   432 non-null    object\n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 13.5+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# There are some invalid data types for relevant columns\n",
    "print(image_data.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "69f1e91b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4524      LES-AV-1.png\n",
      "4525      LES-AV-2.png\n",
      "4526      LES-AV-3.png\n",
      "4527      LES-AV-4.png\n",
      "4528      LES-AV-5.png\n",
      "             ...      \n",
      "12444    FIVES-396.png\n",
      "12445    FIVES-397.png\n",
      "12446    FIVES-398.png\n",
      "12447    FIVES-399.png\n",
      "12448    FIVES-400.png\n",
      "Name: image_names, Length: 432, dtype: string\n"
     ]
    }
   ],
   "source": [
    "# Change datatypes to the desired values\n",
    "image_data['types'] = image_data['types'].astype('string')\n",
    "image_data['fundus'] = image_data['fundus'].astype('string')\n",
    "image_data['names'] = image_data['names'].astype('string')\n",
    "image_data['image_names'] = image_data['names'] + '.png'\n",
    "print(image_data['image_names'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a984dadd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 432 entries, 4524 to 12448\n",
      "Data columns (total 4 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   types        432 non-null    string\n",
      " 1   fundus       432 non-null    string\n",
      " 2   names        432 non-null    string\n",
      " 3   image_names  432 non-null    string\n",
      "dtypes: string(4)\n",
      "memory usage: 16.9 KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(image_data.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7f786ae3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of healthy samples: 261\n",
      "Number of unhealthy samples: 171\n"
     ]
    }
   ],
   "source": [
    "# Randomize data \n",
    "image_data_random = image_data.sample(frac=1, random_state=1)\n",
    "\n",
    "# Split into healthy and glaucoma positive sets\n",
    "healthy = image_data_random[image_data_random['types'] == \"0\"]\n",
    "glaucoma = image_data_random[image_data_random['types'] == \"1\"]\n",
    "\n",
    "print(f\"Number of healthy samples: {len(healthy)}\")\n",
    "print(f\"Number of unhealthy samples: {len(glaucoma)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0425a90c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test size: 152\n",
      "Train size: 280\n"
     ]
    }
   ],
   "source": [
    "# Partition data into test and train sets\n",
    "healthy_train_size = 175\n",
    "glaucoma_train_size = 105\n",
    "\n",
    "healthy_test_subset = image_data_random.head(len(healthy) - healthy_train_size)\n",
    "glaucoma_test_subset = image_data_random.head(len(glaucoma) - glaucoma_train_size)\n",
    "test_subset = pd.concat([healthy_test_subset, glaucoma_test_subset])\n",
    "\n",
    "healthy_train_subset = image_data_random.tail(healthy_train_size)\n",
    "glaucoma_train_subset = image_data_random.tail(glaucoma_train_size)\n",
    "train_subset = pd.concat([healthy_train_subset, glaucoma_train_subset])\n",
    "\n",
    "print(f\"Test size: {len(test_subset)}\")\n",
    "print(f\"Train size: {len(train_subset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d54427e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 280 validated image filenames belonging to 2 classes.\n",
      "Found 152 validated image filenames belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_data_generator = ImageDataGenerator(preprocessing_function= preprocess_input)\n",
    "\n",
    "flow_train_data = train_data_generator.flow_from_dataframe(dataframe=train_subset, \n",
    "                                            batch_size= 8, \n",
    "                                            shuffle=True, \n",
    "                                            x_col=\"image_names\", \n",
    "                                            y_col=\"types\", \n",
    "                                            validate_filenames=True, \n",
    "                                            target_size=(224, 224), \n",
    "                                            directory='full-fundus/full-fundus/', \n",
    "                                            color_mode='rgb')\n",
    "\n",
    "test_data_generator = ImageDataGenerator(preprocessing_function= preprocess_input)\n",
    "\n",
    "flow_test_data = train_data_generator.flow_from_dataframe(dataframe=test_subset, \n",
    "                                            batch_size= 1, \n",
    "                                            shuffle=False, \n",
    "                                            x_col=\"image_names\", \n",
    "                                            y_col=\"types\", \n",
    "                                            validate_filenames=True, \n",
    "                                            target_size=(224, 224), \n",
    "                                            directory='full-fundus/full-fundus/', \n",
    "                                            color_mode='rgb')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c53f954e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ThomasMcBride/anaconda3/lib/python3.11/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:120: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 812ms/step - auc: 0.2720 - binary_accuracy: 0.3458 - loss: 5.5513 - precision: 0.3458 - recall: 0.3458 - val_auc: 0.2999 - val_binary_accuracy: 0.3553 - val_loss: 1.6820 - val_precision: 0.3553 - val_recall: 0.3553 - learning_rate: 1.0000e-05\n",
      "Epoch 2/20\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 220ms/step - auc: 0.5803 - binary_accuracy: 0.5458 - loss: 5.0855 - precision: 0.5458 - recall: 0.5458 - val_auc: 0.0000e+00 - val_binary_accuracy: 0.0000e+00 - val_loss: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - learning_rate: 1.0000e-05\n",
      "Epoch 3/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-29 14:26:53.717459: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n",
      "/Users/ThomasMcBride/anaconda3/lib/python3.11/contextlib.py:155: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
      "  self.gen.throw(typ, value, traceback)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 674ms/step - auc: 0.3656 - binary_accuracy: 0.3708 - loss: 4.6933 - precision: 0.3708 - recall: 0.3708 - val_auc: 0.3088 - val_binary_accuracy: 0.3816 - val_loss: 1.6220 - val_precision: 0.3816 - val_recall: 0.3816 - learning_rate: 8.0000e-06\n",
      "Epoch 4/20\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 201ms/step - auc: 0.4004 - binary_accuracy: 0.4333 - loss: 5.3080 - precision: 0.4333 - recall: 0.4333 - val_auc: 0.0000e+00 - val_binary_accuracy: 0.0000e+00 - val_loss: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - learning_rate: 6.4000e-06\n",
      "Epoch 5/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-29 14:26:56.827554: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 698ms/step - auc: 0.3700 - binary_accuracy: 0.4250 - loss: 4.9389 - precision: 0.4250 - recall: 0.4250 - val_auc: 0.3193 - val_binary_accuracy: 0.3618 - val_loss: 1.5762 - val_precision: 0.3618 - val_recall: 0.3618 - learning_rate: 5.1200e-06\n",
      "Epoch 6/20\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 198ms/step - auc: 0.7054 - binary_accuracy: 0.6167 - loss: 3.1309 - precision: 0.6167 - recall: 0.6167 - val_auc: 0.0000e+00 - val_binary_accuracy: 0.0000e+00 - val_loss: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - learning_rate: 4.0960e-06\n",
      "Epoch 7/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-29 14:26:59.919942: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 721ms/step - auc: 0.5212 - binary_accuracy: 0.5458 - loss: 4.6415 - precision: 0.5458 - recall: 0.5458 - val_auc: 0.3258 - val_binary_accuracy: 0.3684 - val_loss: 1.5451 - val_precision: 0.3684 - val_recall: 0.3684 - learning_rate: 4.0960e-06\n",
      "Epoch 8/20\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 216ms/step - auc: 0.3266 - binary_accuracy: 0.3583 - loss: 5.6049 - precision: 0.3583 - recall: 0.3583 - val_auc: 0.0000e+00 - val_binary_accuracy: 0.0000e+00 - val_loss: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - learning_rate: 3.2768e-06\n",
      "Epoch 9/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-29 14:27:03.121625: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m3/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 193ms/step - auc: 0.4358 - binary_accuracy: 0.4167 - loss: 4.6678 - precision: 0.4167 - recall: 0.4167"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-29 14:27:03.716947: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 609ms/step - auc: 0.4271 - binary_accuracy: 0.4062 - loss: 4.4998 - precision: 0.4062 - recall: 0.4062 - val_auc: 0.3351 - val_binary_accuracy: 0.4079 - val_loss: 1.5216 - val_precision: 0.4079 - val_recall: 0.4079 - learning_rate: 2.6214e-06\n",
      "Epoch 10/20\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 198ms/step - auc: 0.4303 - binary_accuracy: 0.3708 - loss: 4.5439 - precision: 0.3708 - recall: 0.3708 - val_auc: 0.0000e+00 - val_binary_accuracy: 0.0000e+00 - val_loss: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - learning_rate: 2.0972e-06\n",
      "Epoch 11/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-29 14:27:06.194766: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 664ms/step - auc: 0.2953 - binary_accuracy: 0.3125 - loss: 5.1570 - precision: 0.3125 - recall: 0.3125 - val_auc: 0.3404 - val_binary_accuracy: 0.4079 - val_loss: 1.5044 - val_precision: 0.4079 - val_recall: 0.4079 - learning_rate: 1.6777e-06\n",
      "Epoch 12/20\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 203ms/step - auc: 0.6286 - binary_accuracy: 0.6125 - loss: 4.0569 - precision: 0.6125 - recall: 0.6125 - val_auc: 0.0000e+00 - val_binary_accuracy: 0.0000e+00 - val_loss: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - learning_rate: 1.3422e-06\n",
      "Epoch 13/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-29 14:27:09.185058: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 665ms/step - auc: 0.5748 - binary_accuracy: 0.5333 - loss: 3.9151 - precision: 0.5333 - recall: 0.5333 - val_auc: 0.3501 - val_binary_accuracy: 0.4079 - val_loss: 1.4930 - val_precision: 0.4079 - val_recall: 0.4079 - learning_rate: 1.0737e-06\n",
      "Epoch 14/20\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 226ms/step - auc: 0.6315 - binary_accuracy: 0.5500 - loss: 2.5077 - precision: 0.5500 - recall: 0.5500 - val_auc: 0.0000e+00 - val_binary_accuracy: 0.0000e+00 - val_loss: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - learning_rate: 1.0000e-06\n",
      "Epoch 15/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-29 14:27:12.252756: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 658ms/step - auc: 0.5605 - binary_accuracy: 0.5625 - loss: 3.6570 - precision: 0.5625 - recall: 0.5625 - val_auc: 0.3558 - val_binary_accuracy: 0.4079 - val_loss: 1.4843 - val_precision: 0.4079 - val_recall: 0.4079 - learning_rate: 1.0000e-06\n",
      "Epoch 16/20\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 192ms/step - auc: 0.5628 - binary_accuracy: 0.5833 - loss: 3.0928 - precision: 0.5833 - recall: 0.5833 - val_auc: 0.0000e+00 - val_binary_accuracy: 0.0000e+00 - val_loss: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - learning_rate: 1.0000e-06\n",
      "Epoch 17/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-29 14:27:15.192894: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 660ms/step - auc: 0.3804 - binary_accuracy: 0.3833 - loss: 3.7481 - precision: 0.3833 - recall: 0.3833 - val_auc: 0.3624 - val_binary_accuracy: 0.4211 - val_loss: 1.4749 - val_precision: 0.4211 - val_recall: 0.4211 - learning_rate: 1.0000e-06\n",
      "Epoch 18/20\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 130ms/step - auc: 0.4036 - binary_accuracy: 0.3229 - loss: 4.5012 - precision: 0.3229 - recall: 0.3229 - val_auc: 0.0000e+00 - val_binary_accuracy: 0.0000e+00 - val_loss: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - learning_rate: 1.0000e-06\n",
      "Epoch 19/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-29 14:27:17.940281: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n",
      "2024-03-29 14:27:17.945996: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 666ms/step - auc: 0.2190 - binary_accuracy: 0.3125 - loss: 5.4848 - precision: 0.3125 - recall: 0.3125 - val_auc: 0.3679 - val_binary_accuracy: 0.4079 - val_loss: 1.4679 - val_precision: 0.4079 - val_recall: 0.4079 - learning_rate: 1.0000e-06\n",
      "Epoch 20/20\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 202ms/step - auc: 0.3835 - binary_accuracy: 0.3625 - loss: 5.2920 - precision: 0.3625 - recall: 0.3625 - val_auc: 0.0000e+00 - val_binary_accuracy: 0.0000e+00 - val_loss: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - learning_rate: 1.0000e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-29 14:27:21.206419: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n"
     ]
    }
   ],
   "source": [
    "def conv_model(image_size):\n",
    "    \n",
    "    m_input = keras.Input(shape=(image_size, image_size, 3))\n",
    "    transfer = keras.applications.MobileNetV3Large(\n",
    "        weights='imagenet', include_top= False, input_tensor= m_input, alpha=0.75\n",
    "    )\n",
    "    m_output = Dropout(0.5)(transfer.output)\n",
    "    m_output = Conv2D(filters=256, kernel_size=1)(m_output) \n",
    "    m_output = GlobalMaxPool2D()(m_output)\n",
    "    m_output = Dropout(0.5)(m_output)\n",
    "    m_output = Dense(2, activation='softmax')(m_output)\n",
    "\n",
    "    return keras.Model(inputs=m_input, outputs=m_output)\n",
    "\n",
    "model = conv_model(image_size=224)\n",
    "\n",
    "# Reduce the learning rate if an epoch occurs where there is no improvement to the output of the loss function\n",
    "reduce_lr = ReduceLROnPlateau(monitor='loss', factor=0.8, patience=1, min_lr=1e-6)\n",
    "\n",
    "# Using the Adam optimizer with binary cross entropy, compile the model using the given metrics\n",
    "model.compile(optimizer= Adam(1e-5), \n",
    "              loss='binary_crossentropy', \n",
    "              metrics=['binary_accuracy',keras.metrics.AUC(),keras.metrics.Precision(), keras.metrics.Recall()])\n",
    "\n",
    "trained_model = model.fit(flow_train_data, \n",
    "                    steps_per_epoch= len(flow_train_data) // 8,\n",
    "                    validation_data= flow_test_data, \n",
    "                    validation_steps= len(flow_test_data), \n",
    "                    epochs=20, \n",
    "                    callbacks=[reduce_lr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9ca18e73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<keras.src.callbacks.history.History object at 0x157606910>\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 342ms/step\n",
      "[[0.03991543 0.96008456]]\n",
      "Prediction: Healthy, with 96.00845575332642% confidence\n"
     ]
    }
   ],
   "source": [
    "# Demonstration:\n",
    "print(trained_model)\n",
    "img_path = 'full-fundus/full-fundus/OIA-ODIR-TEST-ONLINE-252.png'\n",
    "img = image.load_img(img_path, target_size=(224, 224))\n",
    " \n",
    "img_array_representation = np.expand_dims(image.img_to_array(img), axis=0)\n",
    "img_array_representation = preprocess_input(img_array_representation)  # Assuming preprocess_input is defined in your code\n",
    "\n",
    "prediction = model.predict(img_array_representation)\n",
    "print(prediction)\n",
    "# Interpret the prediction\n",
    "if prediction[0][0] > prediction[0][1]:\n",
    "    print(f\"Prediction: Glaucoma, with {prediction[0][0] * 100}% confidence\")\n",
    "else:\n",
    "    print(f\"Prediction: Healthy, with {prediction[0][1] * 100}% confidence\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bdafa14",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
