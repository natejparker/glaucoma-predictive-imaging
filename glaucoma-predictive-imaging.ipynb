{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aa01142f",
   "metadata": {},
   "source": [
    "Link to Kaggle dataset: https://www.kaggle.com/datasets/deathtrooper/multichannel-glaucoma-benchmark-dataset/data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "edff56cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "import pandas as pd\n",
    "import keras\n",
    "import os\n",
    "from keras.layers import Dense, Activation, Flatten, Dropout, GlobalAveragePooling2D, Conv2D, BatchNormalization, MaxPooling2D, Input, Concatenate, ReLU, AveragePooling2D, UpSampling2D, GlobalMaxPooling2D\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, ModelCheckpoint\n",
    "from tensorflow.keras.optimizers import SGD, Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "be763ad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unzip files for processing\n",
    "with zipfile.ZipFile(\"full-fundus.zip\",\"r\") as zip_ref:\n",
    "    zip_ref.extractall(\"full-fundus\")\n",
    "    \n",
    "with zipfile.ZipFile(\"blood-vessel.zip\",\"r\") as zip_ref:\n",
    "    zip_ref.extractall(\"blood-vessel\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d96726cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in metadata, and filter for a specific subset of images\n",
    "# TODO: will add more variety of images later\n",
    "image_data = pd.read_csv('metadata.csv')\n",
    "image_data = image_data[image_data['names'].str.contains('FIVES', case=False)]\n",
    "image_data = image_data[['types', 'fundus', 'names']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f024d11f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 400 entries, 12049 to 12448\n",
      "Data columns (total 3 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   types   400 non-null    int64 \n",
      " 1   fundus  400 non-null    object\n",
      " 2   names   400 non-null    object\n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 12.5+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# There are some invalid data types for relevant columns\n",
    "print(image_data.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "69f1e91b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12049      FIVES-1.png\n",
      "12050      FIVES-2.png\n",
      "12051      FIVES-3.png\n",
      "12052      FIVES-4.png\n",
      "12053      FIVES-5.png\n",
      "             ...      \n",
      "12444    FIVES-396.png\n",
      "12445    FIVES-397.png\n",
      "12446    FIVES-398.png\n",
      "12447    FIVES-399.png\n",
      "12448    FIVES-400.png\n",
      "Name: image_names, Length: 400, dtype: string\n"
     ]
    }
   ],
   "source": [
    "# Change datatypes to the desired values\n",
    "image_data['types'] = image_data['types'].astype('string')\n",
    "image_data['fundus'] = image_data['fundus'].astype('string')\n",
    "image_data['names'] = image_data['names'].astype('string')\n",
    "image_data['image_names'] = image_data['names'] + '.png'\n",
    "print(image_data['image_names'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "849dceb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 400 entries, 12049 to 12448\n",
      "Data columns (total 4 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   types        400 non-null    string\n",
      " 1   fundus       400 non-null    string\n",
      " 2   names        400 non-null    string\n",
      " 3   image_names  400 non-null    string\n",
      "dtypes: string(4)\n",
      "memory usage: 15.6 KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(image_data.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "920e9f84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of healthy samples: 250\n",
      "Number of unhealthy samples: 150\n"
     ]
    }
   ],
   "source": [
    "# Randomize data \n",
    "image_data_random = image_data.sample(frac=1, random_state=1)\n",
    "\n",
    "# Split into healthy and glaucoma positive sets\n",
    "healthy = image_data_random[image_data_random['types'] == \"0\"]\n",
    "glaucoma = image_data_random[image_data_random['types'] == \"1\"]\n",
    "\n",
    "print(f\"Number of healthy samples: {len(healthy)}\")\n",
    "print(f\"Number of unhealthy samples: {len(glaucoma)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8a756af9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test size: 120\n",
      "Train size: 280\n"
     ]
    }
   ],
   "source": [
    "# Partition data into test and train sets\n",
    "healthy_train_size = 175\n",
    "glaucoma_train_size = 105\n",
    "\n",
    "healthy_test_subset = image_data_random.head(len(healthy) - healthy_train_size)\n",
    "glaucoma_test_subset = image_data_random.head(len(glaucoma) - glaucoma_train_size)\n",
    "test_subset = pd.concat([healthy_test_subset, glaucoma_test_subset])\n",
    "\n",
    "healthy_train_subset = image_data_random.tail(healthy_train_size)\n",
    "glaucoma_train_subset = image_data_random.tail(glaucoma_train_size)\n",
    "train_subset = pd.concat([healthy_train_subset, glaucoma_train_subset])\n",
    "\n",
    "print(f\"Test size: {len(test_subset)}\")\n",
    "print(f\"Train size: {len(train_subset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aeef40ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 280 validated image filenames belonging to 2 classes.\n",
      "Found 120 validated image filenames belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.applications.mobilenet_v3 import preprocess_input \n",
    "\n",
    "train_data_generator = ImageDataGenerator(preprocessing_function= preprocess_input)\n",
    "\n",
    "flow_train_data = train_data_generator.flow_from_dataframe(dataframe=train_subset, \n",
    "                                            batch_size= 2, \n",
    "                                            shuffle=True, \n",
    "                                            x_col=\"image_names\", \n",
    "                                            y_col=\"types\", \n",
    "                                            validate_filenames=True, \n",
    "                                            target_size=(224, 224), \n",
    "                                            directory='full-fundus/full-fundus/', \n",
    "                                            color_mode='rgb')\n",
    "\n",
    "test_data_generator = ImageDataGenerator(preprocessing_function= preprocess_input)\n",
    "\n",
    "flow_test_data = train_data_generator.flow_from_dataframe(dataframe=test_subset, \n",
    "                                            batch_size= 1, \n",
    "                                            shuffle=False, \n",
    "                                            x_col=\"image_names\", \n",
    "                                            y_col=\"types\", \n",
    "                                            validate_filenames=True, \n",
    "                                            target_size=(224, 224), \n",
    "                                            directory='full-fundus/full-fundus/', \n",
    "                                            color_mode='rgb')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c00ddcd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120\n",
      "\u001b[1m 1/93\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m11:14\u001b[0m 7s/step - auc: 0.5000 - binary_accuracy: 0.5000 - loss: 7.4415 - precision: 0.5000 - recall: 1.0000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ThomasMcBride/anaconda3/lib/python3.11/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:120: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m93/93\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 81ms/step - auc: 0.5332 - binary_accuracy: 0.5029 - loss: 5.2713 - precision: 0.5018 - recall: 0.8778 - val_auc: 0.3176 - val_binary_accuracy: 0.4917 - val_loss: 2.4667 - val_precision: 0.4958 - val_recall: 0.9833 - learning_rate: 1.0000e-05\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import GlobalMaxPool2D\n",
    "\n",
    "def conv_model(image_size):\n",
    "    model_input = keras.Input(shape=(image_size, image_size, 3))\n",
    "    transfer = keras.applications.MobileNetV3Large(\n",
    "        weights='imagenet', include_top=False, input_tensor=model_input, alpha=0.75\n",
    "    )\n",
    "\n",
    "    model_output = Dense(2, activation='sigmoid')(Dropout(0.5)(GlobalMaxPool2D()(Conv2D(filters=256, kernel_size=1)(Dropout(0.5)(transfer.output)))))\n",
    "\n",
    "    return keras.Model(inputs=model_input, outputs=model_output)\n",
    "\n",
    "model = conv_model(image_size=224)\n",
    "                     \n",
    "reduce_lr = ReduceLROnPlateau(monitor='loss', factor=0.8, patience=1, min_lr=1e-6)\n",
    "\n",
    "\n",
    "\n",
    "model.compile(optimizer= Adam(1e-5), \n",
    "              loss='binary_crossentropy', \n",
    "              metrics=['binary_accuracy',keras.metrics.AUC(),keras.metrics.Precision(), keras.metrics.Recall()])\n",
    "\n",
    "print(flow_test_data.samples)\n",
    "trained_model = model.fit(flow_train_data, \n",
    "                    steps_per_epoch= (flow_train_data.samples // 3),\n",
    "                    validation_data= flow_test_data, \n",
    "                    validation_steps= len(flow_test_data), \n",
    "                    epochs=1, \n",
    "                    callbacks=[reduce_lr])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f188350",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21a688bd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
