{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "08e3b9b2",
   "metadata": {},
   "source": [
    "Link to Kaggle dataset: https://www.kaggle.com/datasets/deathtrooper/multichannel-glaucoma-benchmark-dataset/data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ecafbbe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "import pandas as pd\n",
    "import keras\n",
    "import os\n",
    "import numpy as np\n",
    "from keras.layers import Dense, Activation, Flatten, Dropout, GlobalAveragePooling2D, Conv2D, BatchNormalization, MaxPooling2D, Input, Concatenate, ReLU, AveragePooling2D, UpSampling2D, GlobalMaxPooling2D\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, ModelCheckpoint\n",
    "from tensorflow.keras.optimizers import SGD, Adam\n",
    "from keras.preprocessing import image\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.applications.mobilenet_v3 import preprocess_input \n",
    "from keras.layers import GlobalMaxPool2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "be763ad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unzip files for processing\n",
    "with zipfile.ZipFile(\"full-fundus.zip\",\"r\") as zip_ref:\n",
    "    zip_ref.extractall(\"full-fundus\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d96726cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in metadata, and filter for a specific subset of images\n",
    "# TODO: will add more variety of images later\n",
    "image_data = pd.read_csv('metadata.csv')\n",
    "image_data = image_data[image_data['names'].str.contains('FIVES', case=True) | image_data['names'].str.contains('HAGIS', case=True)\n",
    "                       | image_data['names'].str.contains('LES-AV', case=True) | image_data['names'].str.contains('G1020', case=True)\n",
    "                       | image_data['names'].str.contains('OIA', case=True) | image_data['names'].str.contains('ORIGA', case=True)]\n",
    "#g1020 = image_data[image_data['names'].str.contains('G1020', case=True)]\n",
    "#g1020 = g1020[g1020[\"fundus_oc_seg\"] != \"Not Visible\"]\n",
    "\n",
    "#image_data = pd.concat([subset_image_data, g1020])\n",
    "image_data = image_data[['types', 'fundus', 'names']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "396d7dcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 6596 entries, 0 to 12448\n",
      "Data columns (total 3 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   types   6596 non-null   int64 \n",
      " 1   fundus  6596 non-null   object\n",
      " 2   names   6596 non-null   object\n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 206.1+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# There are some invalid data types for relevant columns\n",
    "print(image_data.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "69f1e91b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change datatypes to the desired values\n",
    "image_data['types'] = image_data['types'].astype('string')\n",
    "image_data['fundus'] = image_data['fundus'].astype('string')\n",
    "image_data['names'] = image_data['names'].astype('string')\n",
    "image_data['image_names'] = image_data['names'] + '.png'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f881569b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 6596 entries, 0 to 12448\n",
      "Data columns (total 4 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   types        6596 non-null   string\n",
      " 1   fundus       6596 non-null   string\n",
      " 2   names        6596 non-null   string\n",
      " 3   image_names  6596 non-null   string\n",
      "dtypes: string(4)\n",
      "memory usage: 257.7 KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(image_data.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7486279f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of healthy samples: 5618\n",
      "Number of unhealthy samples: 926\n",
      "Number of unhealthy samples: 52\n"
     ]
    }
   ],
   "source": [
    "# Randomize data \n",
    "image_data_random = image_data.sample(frac=1, random_state=1)\n",
    "\n",
    "# Split into healthy and glaucoma positive sets\n",
    "healthy = image_data_random[image_data_random['types'] == \"0\"]\n",
    "glaucoma = image_data_random[image_data_random['types'] == \"1\"]\n",
    "inconclusive = image_data_random[image_data_random['types'] == \"-1\"]\n",
    "\n",
    "print(f\"Number of healthy samples: {len(healthy)}\")\n",
    "print(f\"Number of unhealthy samples: {len(glaucoma)}\")\n",
    "print(f\"Number of inconclusive samples: {len(inconclusive)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d6e6dcee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test size: 2098\n",
      "Train size: 4498\n"
     ]
    }
   ],
   "source": [
    "# Partition data into test and train sets\n",
    "healthy_train_size = 3932\n",
    "glaucoma_train_size = 530\n",
    "inconclusive_train_size = 36\n",
    "\n",
    "healthy_test_subset = image_data_random.head(len(healthy) - healthy_train_size)\n",
    "glaucoma_test_subset = image_data_random.head(len(glaucoma) - glaucoma_train_size)\n",
    "inconclusive_test_subset = image_data_random.head(len(inconclusive) - inconclusive_train_size)\n",
    "test_subset = pd.concat([healthy_test_subset, glaucoma_test_subset, inconclusive_test_subset])\n",
    "\n",
    "healthy_train_subset = image_data_random.tail(healthy_train_size)\n",
    "glaucoma_train_subset = image_data_random.tail(glaucoma_train_size)\n",
    "inconclusive_train_subset = image_data_random.tail(inconclusive_train_size)\n",
    "train_subset = pd.concat([healthy_train_subset, glaucoma_train_subset, inconclusive_train_subset])\n",
    "\n",
    "print(f\"Test size: {len(test_subset)}\")\n",
    "print(f\"Train size: {len(train_subset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eb365185",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4498 validated image filenames belonging to 3 classes.\n",
      "Found 2098 validated image filenames belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "train_data_generator = ImageDataGenerator(preprocessing_function= preprocess_input)\n",
    "\n",
    "flow_train_data = train_data_generator.flow_from_dataframe(dataframe=train_subset, \n",
    "                                            batch_size= 8, \n",
    "                                            shuffle=True, \n",
    "                                            x_col=\"image_names\", \n",
    "                                            y_col=\"types\", \n",
    "                                            validate_filenames=True, \n",
    "                                            target_size=(224, 224), \n",
    "                                            directory='full-fundus/full-fundus/', \n",
    "                                            color_mode='rgb')\n",
    "\n",
    "test_data_generator = ImageDataGenerator(preprocessing_function= preprocess_input)\n",
    "\n",
    "flow_test_data = train_data_generator.flow_from_dataframe(dataframe=test_subset, \n",
    "                                            batch_size= 1, \n",
    "                                            shuffle=False, \n",
    "                                            x_col=\"image_names\", \n",
    "                                            y_col=\"types\", \n",
    "                                            validate_filenames=True, \n",
    "                                            target_size=(224, 224), \n",
    "                                            directory='full-fundus/full-fundus/', \n",
    "                                            color_mode='rgb')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a0c256c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ThomasMcBride/anaconda3/lib/python3.11/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:120: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m94s\u001b[0m 601ms/step - accuracy: 0.2496 - loss: 1.1617 - val_accuracy: 0.0362 - val_loss: 1.2950 - learning_rate: 1.0000e-06\n",
      "Epoch 2/4\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 350ms/step - accuracy: 0.3305 - loss: 1.1128 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00 - learning_rate: 1.0000e-06\n",
      "Epoch 3/4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-30 12:20:54.905506: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n",
      "/Users/ThomasMcBride/anaconda3/lib/python3.11/contextlib.py:155: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
      "  self.gen.throw(typ, value, traceback)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m107s\u001b[0m 768ms/step - accuracy: 0.3209 - loss: 1.1224 - val_accuracy: 0.0715 - val_loss: 1.2722 - learning_rate: 1.0000e-06\n",
      "Epoch 4/4\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 310ms/step - accuracy: 0.3220 - loss: 1.1203 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00 - learning_rate: 1.0000e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-30 12:23:25.586009: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n"
     ]
    }
   ],
   "source": [
    "def conv_model(image_size):\n",
    "    \n",
    "    m_input = keras.Input(shape=(image_size, image_size, 3))\n",
    "    transfer = keras.applications.MobileNetV3Large(\n",
    "        weights='imagenet', include_top= False, input_tensor= m_input, alpha=0.75\n",
    "    )\n",
    "    m_output = Dropout(0.5)(transfer.output)\n",
    "    m_output = Conv2D(filters=256, kernel_size=1)(m_output) \n",
    "    m_output = GlobalMaxPool2D()(m_output)\n",
    "    m_output = Dropout(0.5)(m_output)\n",
    "    m_output = Dense(3, activation='softmax')(m_output)\n",
    "\n",
    "    return keras.Model(inputs=m_input, outputs=m_output)\n",
    "\n",
    "model = conv_model(image_size=224)\n",
    "\n",
    "# Reduce the learning rate if an epoch occurs where there is no improvement to the output of the loss function\n",
    "reduce_lr = ReduceLROnPlateau(monitor='accuracy', factor=0.8, patience=1, min_lr=1e-6)\n",
    "\n",
    "# Using the Adam optimizer with binary cross entropy, compile the model using the given metrics\n",
    "model.compile(optimizer= Adam(1e-6), \n",
    "              loss='hinge', \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "trained_model = model.fit(flow_train_data, \n",
    "                    steps_per_epoch= len(flow_train_data) // 4,\n",
    "                    validation_data= flow_test_data, \n",
    "                    validation_steps= len(flow_test_data), \n",
    "                    epochs=4, \n",
    "                    callbacks=[reduce_lr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "72fda9c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 663ms/step\n",
      "[[9.9612159e-01 3.1514929e-07 3.8780558e-03]]\n",
      "Prediction: Glaucoma, with 99.61215853691101% confidence\n"
     ]
    }
   ],
   "source": [
    "# Demonstration:\n",
    "img_path = 'full-fundus/full-fundus/PAPILA-1.png'\n",
    "img = image.load_img(img_path, target_size=(224, 224))\n",
    " \n",
    "img_array_representation = np.expand_dims(image.img_to_array(img), axis=0)\n",
    "img_array_representation = preprocess_input(img_array_representation)\n",
    "\n",
    "prediction = model.predict(img_array_representation)\n",
    "print(prediction)\n",
    "# Interpret the prediction\n",
    "if prediction[0][0] > prediction[0][1] and prediction[0][0] > prediction[0][2]:\n",
    "    print(f\"Prediction: Glaucoma, with {prediction[0][0] * 100}% confidence\")\n",
    "elif prediction[0][1] > prediction[0][0] and prediction[0][1] > prediction[0][2]:\n",
    "    print(f\"Prediction: Healthy, with {prediction[0][1] * 100}% confidence\")\n",
    "else: \n",
    "    print(f\"Prediction: Glaucoma Suspected, with {prediction[0][2] * 100}% confidence\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ae34228f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "[[9.8653328e-01 1.4083834e-04 1.3325771e-02]]\n",
      "Prediction: Glaucoma, with 98.65332841873169% confidence\n"
     ]
    }
   ],
   "source": [
    "img_path = 'full-fundus/full-fundus/PAPILA-2.png'\n",
    "img = image.load_img(img_path, target_size=(224, 224))\n",
    " \n",
    "img_array_representation = np.expand_dims(image.img_to_array(img), axis=0)\n",
    "img_array_representation = preprocess_input(img_array_representation)  \n",
    "prediction = model.predict(img_array_representation)\n",
    "print(prediction)\n",
    "# Interpret the prediction\n",
    "if prediction[0][0] > prediction[0][1] and prediction[0][0] > prediction[0][2]:\n",
    "    print(f\"Prediction: Glaucoma, with {prediction[0][0] * 100}% confidence\")\n",
    "elif prediction[0][1] > prediction[0][0] and prediction[0][1] > prediction[0][2]:\n",
    "    print(f\"Prediction: Healthy, with {prediction[0][1] * 100}% confidence\")\n",
    "else: \n",
    "    print(f\"Prediction: Glaucoma Suspected, with {prediction[0][2] * 100}% confidence\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4310cbe1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "[[0.10825618 0.09698095 0.7947629 ]]\n",
      "Prediction: Glaucoma Suspected, with 79.4762909412384% confidence\n"
     ]
    }
   ],
   "source": [
    "img_path = 'full-fundus/full-fundus/PAPILA-21.png'\n",
    "img = image.load_img(img_path, target_size=(224, 224))\n",
    " \n",
    "img_array_representation = np.expand_dims(image.img_to_array(img), axis=0)\n",
    "img_array_representation = preprocess_input(img_array_representation) \n",
    "\n",
    "prediction = model.predict(img_array_representation)\n",
    "print(prediction)\n",
    "# Interpret the prediction\n",
    "if prediction[0][0] > prediction[0][1] and prediction[0][0] > prediction[0][2]:\n",
    "    print(f\"Prediction: Glaucoma, with {prediction[0][0] * 100}% confidence\")\n",
    "elif prediction[0][1] > prediction[0][0] and prediction[0][1] > prediction[0][2]:\n",
    "    print(f\"Prediction: Healthy, with {prediction[0][1] * 100}% confidence\")\n",
    "else: \n",
    "    print(f\"Prediction: Glaucoma Suspected, with {prediction[0][2] * 100}% confidence\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4a581e3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "[[0.77369654 0.19523463 0.03106887]]\n",
      "Prediction: Glaucoma, with 77.36965417861938% confidence\n"
     ]
    }
   ],
   "source": [
    "img_path = 'full-fundus/full-fundus/PAPILA-22.png'\n",
    "img = image.load_img(img_path, target_size=(224, 224))\n",
    " \n",
    "img_array_representation = np.expand_dims(image.img_to_array(img), axis=0)\n",
    "img_array_representation = preprocess_input(img_array_representation) \n",
    "\n",
    "prediction = model.predict(img_array_representation)\n",
    "print(prediction)\n",
    "# Interpret the prediction\n",
    "if prediction[0][0] > prediction[0][1] and prediction[0][0] > prediction[0][2]:\n",
    "    print(f\"Prediction: Glaucoma, with {prediction[0][0] * 100}% confidence\")\n",
    "elif prediction[0][1] > prediction[0][0] and prediction[0][1] > prediction[0][2]:\n",
    "    print(f\"Prediction: Healthy, with {prediction[0][1] * 100}% confidence\")\n",
    "else: \n",
    "    print(f\"Prediction: Glaucoma Suspected, with {prediction[0][2] * 100}% confidence\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ce9bb274",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "[[0.02374464 0.10970604 0.8665493 ]]\n",
      "Prediction: Glaucoma Suspected, with 86.65493130683899% confidence\n"
     ]
    }
   ],
   "source": [
    "img_path = 'full-fundus/full-fundus/PAPILA-11.png'\n",
    "img = image.load_img(img_path, target_size=(224, 224))\n",
    " \n",
    "img_array_representation = np.expand_dims(image.img_to_array(img), axis=0)\n",
    "img_array_representation = preprocess_input(img_array_representation) \n",
    "prediction = model.predict(img_array_representation)\n",
    "print(prediction)\n",
    "# Interpret the prediction\n",
    "if prediction[0][0] > prediction[0][1] and prediction[0][0] > prediction[0][2]:\n",
    "    print(f\"Prediction: Glaucoma, with {prediction[0][0] * 100}% confidence\")\n",
    "elif prediction[0][1] > prediction[0][0] and prediction[0][1] > prediction[0][2]:\n",
    "    print(f\"Prediction: Healthy, with {prediction[0][1] * 100}% confidence\")\n",
    "else: \n",
    "    print(f\"Prediction: Glaucoma Suspected, with {prediction[0][2] * 100}% confidence\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "554efed6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
