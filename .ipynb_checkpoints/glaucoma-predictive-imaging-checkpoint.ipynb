{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c9e66a39",
   "metadata": {},
   "source": [
    "Link to Kaggle dataset: https://www.kaggle.com/datasets/deathtrooper/multichannel-glaucoma-benchmark-dataset/data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "312bc02b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "import pandas as pd\n",
    "import keras\n",
    "import os\n",
    "from keras.layers import Dense, Activation, Flatten, Dropout, GlobalAveragePooling2D, Conv2D, BatchNormalization, MaxPooling2D, Input, Concatenate, ReLU, AveragePooling2D, UpSampling2D, GlobalMaxPooling2D\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, ModelCheckpoint\n",
    "from tensorflow.keras.optimizers import SGD, Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "be763ad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unzip files for processing\n",
    "with zipfile.ZipFile(\"full-fundus.zip\",\"r\") as zip_ref:\n",
    "    zip_ref.extractall(\"full-fundus\")\n",
    "    \n",
    "with zipfile.ZipFile(\"blood-vessel.zip\",\"r\") as zip_ref:\n",
    "    zip_ref.extractall(\"blood-vessel\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d96726cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in metadata, and filter for a specific subset of images\n",
    "# TODO: will add more variety of images later\n",
    "image_data = pd.read_csv('metadata.csv')\n",
    "image_data = image_data[image_data['names'].str.contains('FIVES', case=False)]\n",
    "image_data = image_data[['types', 'fundus', 'names']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b62ad775",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 400 entries, 12049 to 12448\n",
      "Data columns (total 3 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   types   400 non-null    int64 \n",
      " 1   fundus  400 non-null    object\n",
      " 2   names   400 non-null    object\n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 12.5+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# There are some invalid data types for relevant columns\n",
    "print(image_data.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "69f1e91b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12049      FIVES-1.png\n",
      "12050      FIVES-2.png\n",
      "12051      FIVES-3.png\n",
      "12052      FIVES-4.png\n",
      "12053      FIVES-5.png\n",
      "             ...      \n",
      "12444    FIVES-396.png\n",
      "12445    FIVES-397.png\n",
      "12446    FIVES-398.png\n",
      "12447    FIVES-399.png\n",
      "12448    FIVES-400.png\n",
      "Name: image_names, Length: 400, dtype: string\n"
     ]
    }
   ],
   "source": [
    "# Change datatypes to the desired values\n",
    "image_data['types'] = image_data['types'].astype('string')\n",
    "image_data['fundus'] = image_data['fundus'].astype('string')\n",
    "image_data['names'] = image_data['names'].astype('string')\n",
    "image_data['image_names'] = image_data['names'] + '.png'\n",
    "print(image_data['image_names'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a16e933f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 400 entries, 12049 to 12448\n",
      "Data columns (total 4 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   types        400 non-null    string\n",
      " 1   fundus       400 non-null    string\n",
      " 2   names        400 non-null    string\n",
      " 3   image_names  400 non-null    string\n",
      "dtypes: string(4)\n",
      "memory usage: 15.6 KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(image_data.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5d2ee661",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of healthy samples: 250\n",
      "Number of unhealthy samples: 150\n"
     ]
    }
   ],
   "source": [
    "# Randomize data \n",
    "image_data_random = image_data.sample(frac=1, random_state=1)\n",
    "\n",
    "# Split into healthy and glaucoma positive sets\n",
    "healthy = image_data_random[image_data_random['types'] == \"0\"]\n",
    "glaucoma = image_data_random[image_data_random['types'] == \"1\"]\n",
    "\n",
    "print(f\"Number of healthy samples: {len(healthy)}\")\n",
    "print(f\"Number of unhealthy samples: {len(glaucoma)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5f17d0cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test size: 120\n",
      "Train size: 280\n"
     ]
    }
   ],
   "source": [
    "# Partition data into test and train sets\n",
    "healthy_train_size = 175\n",
    "glaucoma_train_size = 105\n",
    "\n",
    "healthy_test_subset = image_data_random.head(len(healthy) - healthy_train_size)\n",
    "glaucoma_test_subset = image_data_random.head(len(glaucoma) - glaucoma_train_size)\n",
    "test_subset = pd.concat([healthy_test_subset, glaucoma_test_subset])\n",
    "\n",
    "healthy_train_subset = image_data_random.tail(healthy_train_size)\n",
    "glaucoma_train_subset = image_data_random.tail(glaucoma_train_size)\n",
    "train_subset = pd.concat([healthy_train_subset, glaucoma_train_subset])\n",
    "\n",
    "print(f\"Test size: {len(test_subset)}\")\n",
    "print(f\"Train size: {len(train_subset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7d7d3f0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 280 validated image filenames belonging to 2 classes.\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'DataFrameIterator' object has no attribute 'repeat'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 16\u001b[0m\n\u001b[1;32m      4\u001b[0m train_data_generator \u001b[38;5;241m=\u001b[39m ImageDataGenerator(preprocessing_function\u001b[38;5;241m=\u001b[39m preprocess_input)\n\u001b[1;32m      6\u001b[0m flow_train_data \u001b[38;5;241m=\u001b[39m train_data_generator\u001b[38;5;241m.\u001b[39mflow_from_dataframe(dataframe\u001b[38;5;241m=\u001b[39mtrain_subset, \n\u001b[1;32m      7\u001b[0m                                             batch_size\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m, \n\u001b[1;32m      8\u001b[0m                                             shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     13\u001b[0m                                             directory\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfull-fundus/full-fundus/\u001b[39m\u001b[38;5;124m'\u001b[39m, \n\u001b[1;32m     14\u001b[0m                                             color_mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrgb\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 16\u001b[0m flow_train_data \u001b[38;5;241m=\u001b[39m flow_train_data\u001b[38;5;241m.\u001b[39mrepeat()\n\u001b[1;32m     18\u001b[0m test_data_generator \u001b[38;5;241m=\u001b[39m ImageDataGenerator(preprocessing_function\u001b[38;5;241m=\u001b[39m preprocess_input)\n\u001b[1;32m     20\u001b[0m flow_test_data \u001b[38;5;241m=\u001b[39m train_data_generator\u001b[38;5;241m.\u001b[39mflow_from_dataframe(dataframe\u001b[38;5;241m=\u001b[39mtest_subset, \n\u001b[1;32m     21\u001b[0m                                             batch_size\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m, \n\u001b[1;32m     22\u001b[0m                                             shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     27\u001b[0m                                             directory\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfull-fundus/full-fundus/\u001b[39m\u001b[38;5;124m'\u001b[39m, \n\u001b[1;32m     28\u001b[0m                                             color_mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrgb\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'DataFrameIterator' object has no attribute 'repeat'"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.applications.mobilenet_v3 import preprocess_input \n",
    "\n",
    "train_data_generator = ImageDataGenerator(preprocessing_function= preprocess_input)\n",
    "\n",
    "flow_train_data = train_data_generator.flow_from_dataframe(dataframe=train_subset, \n",
    "                                            batch_size= 2, \n",
    "                                            shuffle=True, \n",
    "                                            x_col=\"image_names\", \n",
    "                                            y_col=\"types\", \n",
    "                                            validate_filenames=True, \n",
    "                                            target_size=(224, 224), \n",
    "                                            directory='full-fundus/full-fundus/', \n",
    "                                            color_mode='rgb')\n",
    "\n",
    "test_data_generator = ImageDataGenerator(preprocessing_function= preprocess_input)\n",
    "\n",
    "flow_test_data = train_data_generator.flow_from_dataframe(dataframe=test_subset, \n",
    "                                            batch_size= 1, \n",
    "                                            shuffle=False, \n",
    "                                            x_col=\"image_names\", \n",
    "                                            y_col=\"types\", \n",
    "                                            validate_filenames=True, \n",
    "                                            target_size=(224, 224), \n",
    "                                            directory='full-fundus/full-fundus/', \n",
    "                                            color_mode='rgb')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b78535a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import GlobalMaxPool2D\n",
    "\n",
    "def conv_model(image_size, num_classes):\n",
    "    model_input = keras.Input(shape=(image_size, image_size, 3))\n",
    "    transfer = keras.applications.MobileNetV3Large(\n",
    "        weights='imagenet', include_top=False, input_tensor=model_input, alpha=0.75\n",
    "    )\n",
    "\n",
    "    x = transfer.output\n",
    "    x = Dropout(0.5)(x)\n",
    "\n",
    "    x = Conv2D(filters=256, kernel_size=1)(x)\n",
    "\n",
    "    x = GlobalMaxPool2D()(x)\n",
    "\n",
    "    x = Dropout(0.5)(x)\n",
    "\n",
    "    model_output = Dense(2, activation='sigmoid')(x)\n",
    "\n",
    "    return keras.Model(inputs=model_input, outputs=model_output)\n",
    "\n",
    "model = conv_model(image_size=224, num_classes=1)\n",
    "                     \n",
    "reduce_lr = ReduceLROnPlateau(monitor='loss', factor=0.8, patience=1, min_lr=1e-6)\n",
    "\n",
    "\n",
    "\n",
    "model.compile(optimizer=Adam(1e-4), \n",
    "              loss='binary_crossentropy', \n",
    "              metrics=['binary_accuracy',keras.metrics.AUC(),keras.metrics.Precision(), keras.metrics.Recall()])\n",
    "\n",
    "print(flow_train_data.samples // 20)\n",
    "trained_model = model.fit(flow_train_data, \n",
    "                    steps_per_epoch= flow_train_data.samples // 20,\n",
    "                    validation_data= flow_test_data, \n",
    "                    validation_steps= len(flow_test_data), \n",
    "                    epochs=14, \n",
    "                    callbacks=[reduce_lr])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9af7aed2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10b0a559",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
