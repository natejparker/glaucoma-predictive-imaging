{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2ad9f24f",
   "metadata": {},
   "source": [
    "Link to Kaggle dataset: https://www.kaggle.com/datasets/deathtrooper/multichannel-glaucoma-benchmark-dataset/data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f8fdab65",
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "import pandas as pd\n",
    "import keras\n",
    "import os\n",
    "from keras.layers import Dense, Activation, Flatten, Dropout, GlobalAveragePooling2D, Conv2D, BatchNormalization, MaxPooling2D, Input, Concatenate, ReLU, AveragePooling2D, UpSampling2D, GlobalMaxPooling2D\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, ModelCheckpoint\n",
    "from tensorflow.keras.optimizers import SGD, Adam\n",
    "from keras.preprocessing import image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "be763ad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unzip files for processing\n",
    "with zipfile.ZipFile(\"full-fundus.zip\",\"r\") as zip_ref:\n",
    "    zip_ref.extractall(\"full-fundus\")\n",
    "    \n",
    "with zipfile.ZipFile(\"blood-vessel.zip\",\"r\") as zip_ref:\n",
    "    zip_ref.extractall(\"blood-vessel\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d96726cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in metadata, and filter for a specific subset of images\n",
    "# TODO: will add more variety of images later\n",
    "image_data = pd.read_csv('metadata.csv')\n",
    "image_data = image_data[image_data['names'].str.contains('FIVES', case=False)]\n",
    "image_data = image_data[['types', 'fundus', 'names']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "154b9dcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 400 entries, 12049 to 12448\n",
      "Data columns (total 3 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   types   400 non-null    int64 \n",
      " 1   fundus  400 non-null    object\n",
      " 2   names   400 non-null    object\n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 12.5+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# There are some invalid data types for relevant columns\n",
    "print(image_data.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "69f1e91b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12049      FIVES-1.png\n",
      "12050      FIVES-2.png\n",
      "12051      FIVES-3.png\n",
      "12052      FIVES-4.png\n",
      "12053      FIVES-5.png\n",
      "             ...      \n",
      "12444    FIVES-396.png\n",
      "12445    FIVES-397.png\n",
      "12446    FIVES-398.png\n",
      "12447    FIVES-399.png\n",
      "12448    FIVES-400.png\n",
      "Name: image_names, Length: 400, dtype: string\n"
     ]
    }
   ],
   "source": [
    "# Change datatypes to the desired values\n",
    "image_data['types'] = image_data['types'].astype('string')\n",
    "image_data['fundus'] = image_data['fundus'].astype('string')\n",
    "image_data['names'] = image_data['names'].astype('string')\n",
    "image_data['image_names'] = image_data['names'] + '.png'\n",
    "print(image_data['image_names'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "68b79851",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 400 entries, 12049 to 12448\n",
      "Data columns (total 4 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   types        400 non-null    string\n",
      " 1   fundus       400 non-null    string\n",
      " 2   names        400 non-null    string\n",
      " 3   image_names  400 non-null    string\n",
      "dtypes: string(4)\n",
      "memory usage: 15.6 KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(image_data.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d89aaa7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of healthy samples: 250\n",
      "Number of unhealthy samples: 150\n"
     ]
    }
   ],
   "source": [
    "# Randomize data \n",
    "image_data_random = image_data.sample(frac=1, random_state=1)\n",
    "\n",
    "# Split into healthy and glaucoma positive sets\n",
    "healthy = image_data_random[image_data_random['types'] == \"0\"]\n",
    "glaucoma = image_data_random[image_data_random['types'] == \"1\"]\n",
    "\n",
    "print(f\"Number of healthy samples: {len(healthy)}\")\n",
    "print(f\"Number of unhealthy samples: {len(glaucoma)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bdf1aab8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test size: 120\n",
      "Train size: 280\n"
     ]
    }
   ],
   "source": [
    "# Partition data into test and train sets\n",
    "healthy_train_size = 175\n",
    "glaucoma_train_size = 105\n",
    "\n",
    "healthy_test_subset = image_data_random.head(len(healthy) - healthy_train_size)\n",
    "glaucoma_test_subset = image_data_random.head(len(glaucoma) - glaucoma_train_size)\n",
    "test_subset = pd.concat([healthy_test_subset, glaucoma_test_subset])\n",
    "\n",
    "healthy_train_subset = image_data_random.tail(healthy_train_size)\n",
    "glaucoma_train_subset = image_data_random.tail(glaucoma_train_size)\n",
    "train_subset = pd.concat([healthy_train_subset, glaucoma_train_subset])\n",
    "\n",
    "print(f\"Test size: {len(test_subset)}\")\n",
    "print(f\"Train size: {len(train_subset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6397752b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 280 validated image filenames belonging to 2 classes.\n",
      "Found 120 validated image filenames belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.applications.mobilenet_v3 import preprocess_input \n",
    "\n",
    "train_data_generator = ImageDataGenerator(preprocessing_function= preprocess_input)\n",
    "\n",
    "flow_train_data = train_data_generator.flow_from_dataframe(dataframe=train_subset, \n",
    "                                            batch_size= 8, \n",
    "                                            shuffle=True, \n",
    "                                            x_col=\"image_names\", \n",
    "                                            y_col=\"types\", \n",
    "                                            validate_filenames=True, \n",
    "                                            target_size=(224, 224), \n",
    "                                            directory='full-fundus/full-fundus/', \n",
    "                                            color_mode='rgb')\n",
    "\n",
    "test_data_generator = ImageDataGenerator(preprocessing_function= preprocess_input)\n",
    "\n",
    "flow_test_data = train_data_generator.flow_from_dataframe(dataframe=test_subset, \n",
    "                                            batch_size= 1, \n",
    "                                            shuffle=False, \n",
    "                                            x_col=\"image_names\", \n",
    "                                            y_col=\"types\", \n",
    "                                            validate_filenames=True, \n",
    "                                            target_size=(224, 224), \n",
    "                                            directory='full-fundus/full-fundus/', \n",
    "                                            color_mode='rgb')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9b715430",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ThomasMcBride/anaconda3/lib/python3.11/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:120: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 802ms/step - auc: 0.5827 - binary_accuracy: 0.5063 - loss: 4.1198 - precision: 0.5045 - recall: 0.8917 - val_auc: 0.3353 - val_binary_accuracy: 0.4625 - val_loss: 1.6265 - val_precision: 0.4737 - val_recall: 0.6750 - learning_rate: 1.0000e-05\n",
      "Epoch 2/8\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 236ms/step - auc: 0.4259 - binary_accuracy: 0.5271 - loss: 4.5874 - precision: 0.5173 - recall: 0.8250 - val_auc: 0.0000e+00 - val_binary_accuracy: 0.0000e+00 - val_loss: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - learning_rate: 1.0000e-05\n",
      "Epoch 3/8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-29 09:47:57.973967: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n",
      "/Users/ThomasMcBride/anaconda3/lib/python3.11/contextlib.py:155: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
      "  self.gen.throw(typ, value, traceback)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 587ms/step - auc: 0.4371 - binary_accuracy: 0.4250 - loss: 4.4563 - precision: 0.4479 - recall: 0.6375 - val_auc: 0.3356 - val_binary_accuracy: 0.4708 - val_loss: 1.5994 - val_precision: 0.4793 - val_recall: 0.6750 - learning_rate: 8.0000e-06\n",
      "Epoch 4/8\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 237ms/step - auc: 0.5120 - binary_accuracy: 0.5688 - loss: 3.7787 - precision: 0.5463 - recall: 0.8083 - val_auc: 0.0000e+00 - val_binary_accuracy: 0.0000e+00 - val_loss: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - learning_rate: 6.4000e-06\n",
      "Epoch 5/8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-29 09:48:00.937318: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 580ms/step - auc: 0.5143 - binary_accuracy: 0.5375 - loss: 3.8440 - precision: 0.5333 - recall: 0.7167 - val_auc: 0.3360 - val_binary_accuracy: 0.4792 - val_loss: 1.5811 - val_precision: 0.4850 - val_recall: 0.6750 - learning_rate: 5.1200e-06\n",
      "Epoch 6/8\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 202ms/step - auc: 0.5909 - binary_accuracy: 0.6438 - loss: 3.3726 - precision: 0.5926 - recall: 0.9125 - val_auc: 0.0000e+00 - val_binary_accuracy: 0.0000e+00 - val_loss: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - learning_rate: 4.0960e-06\n",
      "Epoch 7/8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-29 09:48:03.710004: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 596ms/step - auc: 0.4493 - binary_accuracy: 0.4396 - loss: 5.5110 - precision: 0.4521 - recall: 0.5958 - val_auc: 0.3383 - val_binary_accuracy: 0.4708 - val_loss: 1.5701 - val_precision: 0.4788 - val_recall: 0.6583 - learning_rate: 4.0960e-06\n",
      "Epoch 8/8\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 236ms/step - auc: 0.3614 - binary_accuracy: 0.4167 - loss: 5.5175 - precision: 0.4479 - recall: 0.7000 - val_auc: 0.0000e+00 - val_binary_accuracy: 0.0000e+00 - val_loss: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - learning_rate: 3.2768e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-29 09:48:06.640029: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import GlobalMaxPool2D\n",
    "\n",
    "def conv_model(image_size):\n",
    "    model_input = keras.Input(shape=(image_size, image_size, 3))\n",
    "    transfer = keras.applications.MobileNetV3Large(\n",
    "        weights='imagenet', include_top=False, input_tensor=model_input, alpha=0.75\n",
    "    )\n",
    "\n",
    "    model_output = Dense(2, activation='sigmoid')(Dropout(0.5)(GlobalMaxPool2D()(Conv2D(filters=256, kernel_size=1)(Dropout(0.5)(transfer.output)))))\n",
    "\n",
    "    return keras.Model(inputs=model_input, outputs=model_output)\n",
    "\n",
    "model = conv_model(image_size=224)\n",
    "                     \n",
    "reduce_lr = ReduceLROnPlateau(monitor='loss', factor=0.8, patience=1, min_lr=1e-6)\n",
    "\n",
    "\n",
    "\n",
    "model.compile(optimizer= Adam(1e-5), \n",
    "              loss='binary_crossentropy', \n",
    "              metrics=['binary_accuracy',keras.metrics.AUC(),keras.metrics.Precision(), keras.metrics.Recall()])\n",
    "\n",
    "\n",
    "trained_model = model.fit(flow_train_data, \n",
    "                    steps_per_epoch= len(flow_train_data) // 8,\n",
    "                    validation_data= flow_test_data, \n",
    "                    validation_steps= len(flow_test_data), \n",
    "                    epochs=8, \n",
    "                    callbacks=[reduce_lr])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81d125f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfdec7c7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
